# Mapping the application

## User-Directed Spidering

1. Configure the browser to send requests to the proxy/capture software
2. Browse the entire application normally, attempting to visit every link/URL you discover, submitting every form, and proceeding through all multi-step functions to completion. Try browsing with Javascript enabled and disabled, and with cookies enabled and disabled. Many applications can handle various browser configurations, and you may reach different content and code paths within the application
3. Review the site map generated by the proxy/spider tool, and identify any application content or function that you did not browse manually. Establish how the spider enumerated each item
4. Optionally, tell the tool to actively spider the site using all of the already enumerated content as a starting point. To do this, first identify any URLs that are dangerous or likely to break the application session, and configure the spider to exclude these from its scope

The site map generated by the proxy/spider tool contains a wealth of information about the target application, which will be useful later in identifying the various attack surfaces exposed by the application.

## Brute-Force Techniques

1. Make some manual requests for known valid and invalid resources, take note how the server handles them
2. Use the site map generated through the user-directed spidering as basis for automated discovery
3. Make automated requests for common filenames and directories for each known path in the application, use information from step 1 in the spidering tool to highlight valid or invalid requests
4. Capture the responsed from the server and manually review them
5. Repeat for every new discovered

## Inference from Published Content

1. Review the results of your user-directed spidering and automated spidering (brute-force). From those compile a list of all enumerated subdirectories, file stems and file extensions
2. Review them to identify any naming schemes (for example, known filenames _AddUser.ext_ and _DeleteUser.ext_ show the developer's naming scheme, which may lead to fine-tune the brute-force tool with the pattern *User.ext where * may be _Edit_, _Block_...)
3. In case of static resources, the naming scheme may contain dates and numbers such as _annualtext2009.ext_, _annualtext2010.ext_ and so on...
4.  Review all client-side HTML and Javascript to identify any clue to hidden server-side content
5. Add to the lists of enumerated items any further potential names based on what you have discovered so far, also add to the file extension list common extensions such as .txt, .bak, .src, .inc and .old. Also extension of development language(s) in use in the application
6. Search for temporary files that developers tools and file editors may have left behind (such as _.DS\_Store_, _file.php[--]-1 or .tmp)
7. Combine the lists of directories, file stems and file extensions to request large numbers of potential resources
8. Where a consistent naming scheme has been identified, a more focused brute-force must be performed
9. Repeat all steps recursively using the new enumerated content and patterns as the basis for further user-directed spidering and automated content discovery